from multiprocessing.managers import BaseManager
from multiprocessing import Process
import time
import uuid
from typing import List, Tuple, Dict

import numpy as np
from data_generator.tiingo_data_service import TiingoDataService
from data_generator.polygon_data_service import PolygonDataService
from time_util.time_util import TimeUtil

from vali_objects.vali_config import TradePair
from vali_objects.position import Position
from vali_objects.utils.vali_utils import ValiUtils
import bittensor as bt
from concurrent.futures import ThreadPoolExecutor, TimeoutError as FuturesTimeoutError

from vali_objects.vali_dataclasses.price_source import PriceSource
from statistics import median

class LivePriceFetcherClient:
    """
    Wrapper around the LivePriceFetcher RPC client that performs periodic health checks.
    Health checks run inline on the main thread when methods are called.
    """

    class ClientManager(BaseManager):
        pass

    ClientManager.register('LivePriceFetcher')

    def __init__(self, secrets, address=('localhost', 50000), disable_ws=False, ipc_manager=None, is_backtesting=False, slack_notifier=None):
        """
        Initialize client and start the server process.

        Args:
            secrets: Dictionary containing API keys for data services
            address: Tuple of (host, port) for the RPC server
            disable_ws: Whether to disable websocket connections
            ipc_manager: IPC manager for shared memory
            is_backtesting: Whether running in backtesting mode
            slack_notifier: SlackNotifier instance for error notifications
        """
        self._secrets = secrets
        self._address = address
        self._disable_ws = disable_ws
        self._ipc_manager = ipc_manager
        self._is_backtesting = is_backtesting
        self._slack_notifier = slack_notifier
        self._max_retries = 5
        self._health_check_interval_ms = 60 * 1000
        self._last_health_check_time = 0
        self._consecutive_failures = 0
        self._client = None
        self._server_process = None
        self._authkey = None

        # Start server and connect
        self._start_server()

    def _start_server(self, restart=False):
        if restart:
            bt.logging.warning("Restarting LivePriceFetcher server...")

            # Terminate the old process if it exists
            # Note: We don't check is_alive() because this may be called from a different process
            # (HealthChecker daemon) which cannot check the status of processes it didn't create.
            # terminate() and kill() are safe to call on already-dead processes.
            if self._server_process:
                bt.logging.info("Terminating old LivePriceFetcher server process...")
                self._server_process.terminate()
                self._server_process.join(timeout=5)

                # Force kill if it didn't terminate
                bt.logging.info("Force killing LivePriceFetcher server process (if still alive)...")
                self._server_process.kill()
                self._server_process.join(timeout=2)

        # Generate new authkey for security
        self._authkey = str(uuid.uuid4()).encode()

        # Start the server process
        bt.logging.info("Starting LivePriceFetcher server process...")
        self._server_process = Process(
            target=LivePriceFetcherServer,
            args=(self._secrets,),
            kwargs={
                'address': self._address,
                'authkey': self._authkey,
                'disable_ws': self._disable_ws,
                'ipc_manager': self._ipc_manager,
                'is_backtesting': self._is_backtesting,
                'slack_notifier': self._slack_notifier
            },
            daemon=True
        )
        self._server_process.start()

        # Wait minimum time for server to initialize before attempting connection
        bt.logging.info("Waiting for LivePriceFetcher server to initialize...")
        time.sleep(2)

        # Connect to the server - this verifies the server is actually working
        # If connection fails, connect() will raise an exception
        self.connect()

        # Reset failure counter
        self._consecutive_failures = 0

        if restart:
            bt.logging.success("LivePriceFetcher server restarted successfully")
            if self._slack_notifier:
                self._slack_notifier.send_message(
                    f"âœ… LivePriceFetcher Server Restarted Successfully\n"
                    f"Server is now operational and serving price data.",
                    level="info"
                )

    def connect(self):
        bt.logging.info(f"Attempting to connect to LivePriceFetcher server at {self._address}")
        for attempt in range(self._max_retries):
            try:
                manager = self.ClientManager(address=self._address, authkey=self._authkey)
                manager.connect()
                bt.logging.success(f"Successfully connected to LivePriceFetcher server")
                self._client = manager.LivePriceFetcher()
                return
            except Exception as e:
                if attempt < self._max_retries - 1:
                    bt.logging.warning(f"Failed to connect to LivePriceFetcher server (attempt {attempt + 1}/{self._max_retries}): {e}. Retrying in 1s...")
                    time.sleep(1)
                else:
                    bt.logging.error(f"Failed to connect to LivePriceFetcher server after {self._max_retries} attempts: {e}")
                    raise

    def health_check(self, current_time):
        # Rate limit: only check if enough time has passed
        if current_time - self._last_health_check_time < self._health_check_interval_ms:
            return True  # Skip check, assume healthy

        self._last_health_check_time = current_time

        # Note: We don't check is_alive() here because this method may be called from a different
        # process (HealthChecker daemon), and multiprocessing doesn't allow checking process status
        # across different parent processes. The RPC health_check call below is sufficient to detect
        # if the server is down.

        try:
            # Call the health_check RPC method
            health_status = self._client.health_check()

            if health_status.get("status") == "ok":
                if self._consecutive_failures > 0:
                    recovery_msg = f"LivePriceFetcher server recovered after {self._consecutive_failures} failed health checks"
                    bt.logging.success(recovery_msg)
                    if self._slack_notifier:
                        self._slack_notifier.send_message(
                            f"âœ… LivePriceFetcher Server Recovered!\n"
                            f"Server is healthy after {self._consecutive_failures} failed checks.",
                            level="info"
                        )
                self._consecutive_failures = 0
                bt.logging.trace(f"LivePriceFetcher health check passed: {health_status}")
                return True
            else:
                self._consecutive_failures += 1
                bt.logging.warning(
                    f"LivePriceFetcher health check returned unexpected status: {health_status} "
                    f"(consecutive failures: {self._consecutive_failures})"
                )
                if self._consecutive_failures >= 3:
                    bt.logging.warning("Triggering server restart due to failed health checks...")
                    if self._slack_notifier:
                        self._slack_notifier.send_message(
                            f"ðŸ”„ LivePriceFetcher Server Restart Triggered\n"
                            f"Restarting due to {self._consecutive_failures} failed health checks...",
                            level="warning"
                        )
                    self._start_server(restart=True)
                return False

        except Exception as e:
            self._consecutive_failures += 1
            bt.logging.error(
                f"LivePriceFetcher health check failed: {e} "
                f"(consecutive failures: {self._consecutive_failures})"
            )

            # Trigger restart after 3 consecutive failures
            if self._consecutive_failures >= 3:
                bt.logging.warning("Triggering server restart due to failed health checks...")
                if self._slack_notifier:
                    self._slack_notifier.send_message(
                        f"ðŸ”„ LivePriceFetcher Server Restart Triggered\n"
                        f"Restarting due to {self._consecutive_failures} failed health checks.\n"
                        f"Last error: {str(e)}",
                        level="warning"
                    )
                self._start_server(restart=True)
            return False

    def __getattr__(self, name):
        """
        Proxy all method calls to the underlying client.
        """
        # Proxy the call to the underlying client
        return getattr(self._client, name)

    class HealthChecker:
        """Daemon process that continuously monitors LivePriceFetcher server health"""

        def __init__(self, live_price_fetcher_client, slack_notifier=None):
            self.live_price_fetcher_client = live_price_fetcher_client
            self.slack_notifier = slack_notifier

        def run_update_loop(self):
            from setproctitle import setproctitle
            from shared_objects.error_utils import ErrorUtils
            import traceback

            setproctitle("vali_HealthChecker")
            bt.logging.info("LivePriceFetcherHealthChecker daemon started")

            # Run indefinitely - process will terminate when main process exits (daemon=True)
            while True:
                try:
                    current_time = TimeUtil.now_in_millis()
                    self.live_price_fetcher_client.health_check(current_time)

                    # Sleep for 60 seconds between health checks
                    # The health_check method has its own rate limiting (60s interval)
                    # so this ensures we check approximately every minute
                    time.sleep(60)

                except Exception as e:
                    error_traceback = traceback.format_exc()
                    bt.logging.error(f"Error in LivePriceFetcherHealthChecker: {e}")
                    bt.logging.error(error_traceback)

                    # Send Slack notification
                    if self.slack_notifier:
                        error_message = ErrorUtils.format_error_for_slack(
                            error=e,
                            traceback_str=error_traceback,
                            include_operation=True,
                            include_timestamp=True
                        )
                        self.slack_notifier.send_message(
                            f"âŒ LivePriceFetcherHealthChecker Error!\n{error_message}",
                            level="error"
                        )

                    # Sleep before retrying
                    time.sleep(60)

class LivePriceFetcherServer:
    """
    Wrapper for the LivePriceFetcher RPC server.
    Instantiating this class starts the server automatically.
    """

    class ServerManager(BaseManager):
        pass

    def __init__(self, secrets, address=('localhost', 50000), authkey=None, disable_ws=False, ipc_manager=None, is_backtesting=False, slack_notifier=None):
        if authkey is None:
            raise ValueError("authkey parameter is required for LivePriceFetcher server")

        # Wrap everything in try/except to catch and report crashes
        try:
            from setproctitle import setproctitle
            from shared_objects.error_utils import ErrorUtils
            import traceback

            setproctitle("vali_LivePriceFetcher")
            bt.logging.info(f"Starting LivePriceFetcher server on {address}...")

            # Create the LivePriceFetcher instance
            live_price_fetcher = LivePriceFetcher(secrets, disable_ws, ipc_manager, is_backtesting)
            bt.logging.info(f"LivePriceFetcher instance created successfully")

            # Register and start the RPC server
            self.ServerManager.register('LivePriceFetcher', callable=lambda: live_price_fetcher)
            manager = self.ServerManager(address=address, authkey=authkey)
            server = manager.get_server()
            bt.logging.success(f"LivePriceFetcher server is now listening and serving requests")

            # Start serving (blocks forever)
            server.serve_forever()

        except Exception as e:
            error_traceback = traceback.format_exc()
            bt.logging.error(f"CRITICAL: LivePriceFetcher server crashed: {e}")
            bt.logging.error(error_traceback)

            # Send critical error notification to Slack
            if slack_notifier:
                error_message = ErrorUtils.format_error_for_slack(
                    error=e,
                    traceback_str=error_traceback,
                    include_operation=True,
                    include_timestamp=True
                )
                slack_notifier.send_message(
                    f"ðŸ’¥ CRITICAL: LivePriceFetcher Server Crashed!\n"
                    f"{error_message}\n"
                    f"Price data services are offline. Manual intervention required.",
                    level="error"
                )

            # Re-raise to ensure process exits with error code
            raise

class LivePriceFetcher:
    def __init__(self, secrets, disable_ws=False, ipc_manager=None, is_backtesting=False):
        self.is_backtesting = is_backtesting
        self.last_health_check_ms = 0
        if "tiingo_apikey" in secrets:
            self.tiingo_data_service = TiingoDataService(api_key=secrets["tiingo_apikey"], disable_ws=disable_ws,
                                                         ipc_manager=ipc_manager)
        else:
            raise Exception("Tiingo API key not found in secrets.json")
        if "polygon_apikey" in secrets:
            self.polygon_data_service = PolygonDataService(api_key=secrets["polygon_apikey"], disable_ws=disable_ws,
                                                           ipc_manager=ipc_manager, is_backtesting=is_backtesting)
        else:
            raise Exception("Polygon API key not found in secrets.json")

    def stop_all_threads(self):
        self.tiingo_data_service.stop_threads()
        self.polygon_data_service.stop_threads()

    def health_check(self) -> dict:
        """
        Health check method for RPC connection between client and server.
        Returns a simple status indicating the server is alive and responsive.
        """
        current_time_ms = TimeUtil.now_in_millis()
        return {
            "status": "ok",
            "timestamp_ms": current_time_ms,
            "is_backtesting": self.is_backtesting
        }

    def is_market_open(self, trade_pair: TradePair) -> bool:
        return self.polygon_data_service.is_market_open(trade_pair)

    def get_unsupported_trade_pairs(self):
        return self.polygon_data_service.UNSUPPORTED_TRADE_PAIRS

    def get_currency_conversion(self, base: str, quote: str):
        return self.polygon_data_service.get_currency_conversion(base=base, quote=quote)

    def unified_candle_fetcher(self, trade_pair, start_date, order_date, timespan="day"):
        return self.polygon_data_service.unified_candle_fetcher(trade_pair, start_date, order_date, timespan=timespan)

    def sorted_valid_price_sources(self, price_events: List[PriceSource | None], current_time_ms: int, filter_recent_only=True) -> List[PriceSource] | None:
        """
        Sorts a list of price events by their recency and validity.
        """
        valid_events = [event for event in price_events if event]
        if not valid_events:
            return None

        best_event = PriceSource.get_winning_event(valid_events, current_time_ms)
        if not best_event:
            return None

        if filter_recent_only and best_event.time_delta_from_now_ms(current_time_ms) > 8000:
            return None

        return PriceSource.non_null_events_sorted(valid_events, current_time_ms)

    def dual_rest_get(
            self,
            trade_pairs: List[TradePair]
    ) -> Tuple[Dict[TradePair, PriceSource], Dict[TradePair, PriceSource]]:
        """
        Fetch REST closes from both Polygon and Tiingo in parallel,
        using ThreadPoolExecutor to run both calls concurrently.
        """
        polygon_results = {}
        tiingo_results = {}
        with ThreadPoolExecutor(max_workers=2) as executor:
            # Submit both REST calls to the executor
            poly_fut = executor.submit(self.polygon_data_service.get_closes_rest, trade_pairs)
            tiingo_fut = executor.submit(self.tiingo_data_service.get_closes_rest, trade_pairs)

            try:
                # Wait for both futures to complete with a 10s timeout
                polygon_results = poly_fut.result(timeout=10)
                tiingo_results = tiingo_fut.result(timeout=10)
            except FuturesTimeoutError:
                poly_fut.cancel()
                tiingo_fut.cancel()
                bt.logging.warning(f"dual_rest_get REST API requests timed out. trade_pairs: {trade_pairs}.")

        return polygon_results, tiingo_results

    def get_ws_price_sources_in_window(self, trade_pair: TradePair, start_ms: int, end_ms: int) -> List[PriceSource]:
        # Utilize get_events_in_range
        poly_sources = self.polygon_data_service.trade_pair_to_recent_events[trade_pair.trade_pair].get_events_in_range(start_ms, end_ms)
        t_sources = self.tiingo_data_service.trade_pair_to_recent_events[trade_pair.trade_pair].get_events_in_range(start_ms, end_ms)
        return poly_sources + t_sources

    def get_latest_price(self, trade_pair: TradePair, time_ms=None) -> Tuple[float, List[PriceSource]] | Tuple[None, None]:
        """
        Gets the latest price for a single trade pair by utilizing WebSocket and possibly REST data sources.
        Tries to get the price as close to time_ms as possible.
        """
        if not time_ms:
            time_ms = TimeUtil.now_in_millis()
        price_sources = self.get_sorted_price_sources_for_trade_pair(trade_pair, time_ms)
        winning_event = PriceSource.get_winning_event(price_sources, time_ms)
        return winning_event.parse_best_best_price_legacy(time_ms), price_sources

    def get_sorted_price_sources_for_trade_pair(self, trade_pair: TradePair, time_ms:int) -> List[PriceSource] | None:
        temp = self.get_tp_to_sorted_price_sources([trade_pair], {trade_pair: time_ms})
        return temp.get(trade_pair)

    def get_tp_to_sorted_price_sources(self, trade_pairs: List[TradePair],
                                       trade_pair_to_last_order_time_ms: Dict[TradePair, int] = None) -> Dict[TradePair, List[PriceSource]]:
        """
        Retrieves the latest prices for multiple trade pairs, leveraging both WebSocket and REST APIs as needed.
        """
        if not trade_pair_to_last_order_time_ms:
            current_time_ms = TimeUtil.now_in_millis()
            trade_pair_to_last_order_time_ms = {tp: current_time_ms for tp in trade_pairs}
        websocket_prices_polygon = self.polygon_data_service.get_closes_websocket(trade_pairs=trade_pairs,
                                                                                  trade_pair_to_last_order_time_ms=trade_pair_to_last_order_time_ms)
        websocket_prices_tiingo_data = self.tiingo_data_service.get_closes_websocket(trade_pairs=trade_pairs,
                                                                                     trade_pair_to_last_order_time_ms=trade_pair_to_last_order_time_ms)
        trade_pairs_needing_rest_data = []

        results = {}

        # Initial check using WebSocket data
        for trade_pair in trade_pairs:
            current_time_ms = trade_pair_to_last_order_time_ms[trade_pair]
            events = [websocket_prices_polygon.get(trade_pair), websocket_prices_tiingo_data.get(trade_pair)]
            sources = self.sorted_valid_price_sources(events, current_time_ms, filter_recent_only=True)
            if sources:
                results[trade_pair] = sources
            else:
                trade_pairs_needing_rest_data.append(trade_pair)

        # Fetch from REST APIs if needed
        if not trade_pairs_needing_rest_data:
            return results

        rest_prices_polygon, rest_prices_tiingo_data = self.dual_rest_get(trade_pairs_needing_rest_data)

        for trade_pair in trade_pairs_needing_rest_data:
            current_time_ms = trade_pair_to_last_order_time_ms[trade_pair]
            sources = self.sorted_valid_price_sources([
                websocket_prices_polygon.get(trade_pair),
                websocket_prices_tiingo_data.get(trade_pair),
                rest_prices_polygon.get(trade_pair),
                rest_prices_tiingo_data.get(trade_pair)
            ], current_time_ms, filter_recent_only=False)
            results[trade_pair] = sources

        return results

    def time_since_last_ws_ping_s(self, trade_pair: TradePair) -> float | None:
        if trade_pair in self.polygon_data_service.UNSUPPORTED_TRADE_PAIRS:
            return None
        now_ms = TimeUtil.now_in_millis()
        t1 = self.polygon_data_service.get_websocket_lag_for_trade_pair_s(tp=trade_pair.trade_pair, now_ms=now_ms)
        t2 = self.tiingo_data_service.get_websocket_lag_for_trade_pair_s(tp=trade_pair.trade_pair, now_ms=now_ms)
        return max([x for x in (t1, t2) if x])

    def filter_outliers(self, unique_data: List[PriceSource]) -> List[PriceSource]:
        """
        Filters out outliers and duplicates from a list of price sources.
        """
        if not unique_data:
            return []

        # Function to calculate bounds
        def calculate_bounds(prices):
            median = np.median(prices)
            # Calculate bounds as 5% less than and more than the median
            lower_bound = median * 0.95
            upper_bound = median * 1.05
            return lower_bound, upper_bound

        # Calculate bounds for each price type
        close_prices = np.array([x.close for x in unique_data])
        # high_prices = np.array([x.high for x in unique_data])
        # low_prices = np.array([x.low for x in unique_data])

        close_lower_bound, close_upper_bound = calculate_bounds(close_prices)
        # high_lower_bound, high_upper_bound = calculate_bounds(high_prices)
        # low_lower_bound, low_upper_bound = calculate_bounds(low_prices)

        # Filter data by checking all price points against their respective bounds
        filtered_data = [x for x in unique_data if close_lower_bound <= x.close <= close_upper_bound]
        # filtered_data = [x for x in unique_data if close_lower_bound <= x.close <= close_upper_bound and
        #                 high_lower_bound <= x.high <= high_upper_bound and
        #                 low_lower_bound <= x.low <= low_upper_bound]

        # Sort the data by timestamp in ascending order
        filtered_data.sort(key=lambda x: x.start_ms, reverse=True)
        return filtered_data

    def parse_price_from_candle_data(self, data: List[PriceSource], trade_pair: TradePair) -> float | None:
        if not data or len(data) == 0:
            # Market is closed for this trade pair
            bt.logging.trace(f"No ps data to parse for realtime price for trade pair {trade_pair.trade_pair_id}. data: {data}")
            return None

        # Data by timestamp in ascending order so that the largest timestamp is first
        return data[0].close

    def get_quote(self, trade_pair: TradePair, processed_ms: int) -> (float, float, int):
        """
        returns the bid and ask quote for a trade_pair at processed_ms. Only Polygon supports point-in-time bid/ask.
        """
        return self.polygon_data_service.get_quote(trade_pair, processed_ms)

    def parse_extreme_price_in_window(self, candle_data: Dict[TradePair, List[PriceSource]], open_position: Position, parse_min: bool = True) -> Tuple[float, PriceSource] | Tuple[None, None]:
        trade_pair = open_position.trade_pair
        dat = candle_data.get(trade_pair)
        if dat is None:
            # Market is closed for this trade pair
            return None, None

        min_allowed_timestamp_ms = open_position.orders[-1].processed_ms
        prices = []
        corresponding_sources = []

        for a in dat:
            if a.end_ms < min_allowed_timestamp_ms:
                continue
            price = a.low if parse_min else a.high
            if price is not None:
                prices.append(price)
                corresponding_sources.append(a)

        if not prices:
            return None, None

        if len(prices) % 2 == 1:
            med_price = median(prices)  # Direct median if the list is odd
        else:
            # If even, choose the lower middle element to ensure it exists in the list
            sorted_prices = sorted(prices)
            middle_index = len(sorted_prices) // 2 - 1
            med_price = sorted_prices[middle_index]

        med_index = prices.index(med_price)
        med_source = corresponding_sources[med_index]

        return med_price, med_source

    def get_candles(self, trade_pairs, start_time_ms, end_time_ms) -> dict:
        ans = {}
        debug = {}
        one_second_rest_candles = self.polygon_data_service.get_candles(
            trade_pairs=trade_pairs, start_time_ms=start_time_ms, end_time_ms=end_time_ms)

        for tp in trade_pairs:
            rest_candles = one_second_rest_candles.get(tp, [])
            ws_candles = self.get_ws_price_sources_in_window(tp, start_time_ms, end_time_ms)
            non_null_sources = list(set(rest_candles + ws_candles))
            filtered_sources = self.filter_outliers(non_null_sources)
            # Get the sources removed to debug
            removed_sources = [x for x in non_null_sources if x not in filtered_sources]
            ans[tp] = filtered_sources
            min_time = min((x.start_ms for x in non_null_sources)) if non_null_sources else 0
            max_time = max((x.end_ms for x in non_null_sources)) if non_null_sources else 0
            debug[
                tp.trade_pair] = f"R{len(rest_candles)}W{len(ws_candles)}U{len(non_null_sources)}T[{(max_time - min_time) / 1000.0:.2f}]"
            if removed_sources:
                mi = min((x.close for x in non_null_sources))
                ma = max((x.close for x in non_null_sources))
                debug[tp.trade_pair] += f" Removed {[x.close for x in removed_sources]} Original min/max {mi}/{ma}"

        bt.logging.info(f"Fetched candles {debug} in window"
                        f" {TimeUtil.millis_to_formatted_date_str(start_time_ms)} to "
                        f"{TimeUtil.millis_to_formatted_date_str(end_time_ms)}")

        # If Polygon has any missing keys, it is intentional and corresponds to a closed market. We don't want to use twelvedata for this TODO: fall back to live price from TD/POLY.
        # if self.twelvedata_available and len(ans) == 0:
        #    bt.logging.info(f"Fetching candles from TD for {[x.trade_pair for x in trade_pairs]} from {start_time_ms} to {end_time_ms}")
        #    closes = self.twelve_data.get_closes(trade_pairs=trade_pairs)
        #    ans.update(closes)
        return ans

    def get_close_at_date(self, trade_pair, timestamp_ms, order=None, verbose=True):
        if self.is_backtesting:
            assert order, 'Must provide order for validation during backtesting'

        price_source = None
        if not self.polygon_data_service.is_market_open(trade_pair, time_ms=timestamp_ms):
            if self.is_backtesting and order and order.src == 0:
                raise Exception(f"Backtesting validation failure: Attempting to price fill during closed market. TP {trade_pair.trade_pair_id} at {TimeUtil.millis_to_formatted_date_str(timestamp_ms)}")
            else:
                price_source = self.polygon_data_service.get_event_before_market_close(trade_pair, timestamp_ms)
                print(f'Used previous close to fill price for {trade_pair.trade_pair_id} at {TimeUtil.millis_to_formatted_date_str(timestamp_ms)}')

        if price_source is None:
            price_source = self.polygon_data_service.get_close_at_date_second(trade_pair=trade_pair, target_timestamp_ms=timestamp_ms)
        if price_source is None:
            price_source = self.polygon_data_service.get_close_at_date_minute_fallback(trade_pair=trade_pair, target_timestamp_ms=timestamp_ms)
            if price_source:
                bt.logging.warning(
                    f"Fell back to Polygon get_date_minute_fallback for price of {trade_pair.trade_pair} at {TimeUtil.timestamp_ms_to_eastern_time_str(timestamp_ms)}, price_source: {price_source}")

        if price_source is None:
            price_source = self.tiingo_data_service.get_close_rest(trade_pair=trade_pair, target_time_ms=timestamp_ms)
            if verbose and price_source is not None:
                bt.logging.warning(
                    f"Fell back to Tiingo get_date for price of {trade_pair.trade_pair} at {TimeUtil.timestamp_ms_to_eastern_time_str(timestamp_ms)}, ms: {timestamp_ms}")


        """
        if price is None:
            price, time_delta = self.polygon_data_service.get_close_in_past_hour_fallback(trade_pair=trade_pair,
                                                                             timestamp_ms=timestamp_ms)
            if price:
                formatted_date = TimeUtil.timestamp_ms_to_eastern_time_str(timestamp_ms)
                bt.logging.warning(
                    f"Fell back to Polygon get_close_in_past_hour_fallback for price of {trade_pair.trade_pair} at {formatted_date}, ms: {timestamp_ms}")
        if price is None:
            formatted_date = TimeUtil.timestamp_ms_to_eastern_time_str(timestamp_ms)
            bt.logging.error(
                f"Failed to get data at ET date {formatted_date} for {trade_pair.trade_pair}. Timestamp ms: {timestamp_ms}."
                f" Ask a team member to investigate this issue.")
        """
        return price_source


if __name__ == "__main__":
    secrets = ValiUtils.get_secrets()
    live_price_fetcher = LivePriceFetcher(secrets, disable_ws=True)
    ans = live_price_fetcher.get_close_at_date(TradePair.TAOUSD, 1733304060475)
    print('@@@@', ans, '@@@@@')
    time.sleep(100000)

    trade_pairs = [TradePair.BTCUSD, TradePair.ETHUSD, ]
    while True:
        for tp in TradePair:
            print(f"{tp.trade_pair}: {live_price_fetcher.get_close(tp)}")
        time.sleep(10)
    # ans = live_price_fetcher.get_closes(trade_pairs)
    # for k, v in ans.items():
    #    print(f"{k.trade_pair_id}: {v}")
    # print("Done")
